# Documentaci贸n del Proyecto: NYC Taxi Analytics

Bienvenido al centro de documentaci贸n del proyecto. Esta gu铆a est谩 organizada por **roles** para facilitar a los nuevos integrantes encontrar la informaci贸n relevante seg煤n su 谩rea de trabajo.

##  Visi贸n General (Lectura Recomendada para Todos)

Antes de profundizar en su 谩rea, se recomienda entender el contexto global del proyecto.

*   **[Arquitectura del Sistema](arquitectura.md)**: Diagrama y explicaci贸n de como interact煤an Docker, Hadoop, Spark, Node.js y React.
*   **[Resumen Ejecutivo - Parte 1](resumen_parte_1.md)**: Origen del proyecto y objetivos iniciales.
*   **[Resumen Ejecutivo - Parte 2](resumen_parte_2.md)**: Evoluci贸n y estado actual.
*   **[Justificaci贸n y Problem谩tica](justificacion_problematica.md)**: An谩lisis formal del problema de Big Data, desaf铆os t茅cnicos y la justificaci贸n de la arquitectura elegida.

---

##  Diagramas y Arquitectura Visual

Para una comprensi贸n r谩pida y visual de todo el sistema:

*   **[Galer铆a de Diagramas del Sistema](diagramas_sistema.md)**: (Consolidado de diagramas Mermaid explicados)
    1.  Despliegue (Docker/Contenedores)
    2.  Flujo General de Datos
    3.  Flujos Detallados por Rol (Infra, API, Frontend)

---

##  Equipo de Infraestructura y Datos (DevOps / Data Engineers)

Si eres responsable de **Docker, Hadoop, Spark** o los **Pipelines de Datos**, esta es tu secci贸n.

1.  **[Gu铆a de Despliegue y Comandos](despliegue_comandos.md)** ( **Cr铆tico**):
    *   C贸mo levantar el entorno con Docker Compose.
    *   Comandos para iniciar, detener y reiniciar servicios.
    *   **C贸mo cargar nuevos datos anuales**.
2.  **[Scripts de Automatizaci贸n](scripts_automatizacion.md)**:
    *   Explicaci贸n t茅cnica de `init.sh`, `verify_env.bat` y `check_api.bat`.
3.  **[Explicaci贸n de Carga y ETL](explicacion_carga.md)**:
    *   Detalle profundo de los jobs de Spark (`load_to_hdfs`, `clean_data`, `analytics`).
    *   C贸mo se procesan los archivos Parquet.

---

## 锔 Equipo Backend (API Developers)

Si trabajas en la **API REST (Node.js/Express)** que sirve los datos al frontend.

1.  **[Documentaci贸n de la API](api_documentacion.md)**:
    *   Endpoints disponibles (V1 y V2).
    *   Estructuras de respuesta JSON.
    *   L贸gica del servicio HDFS (`hdfs.service.js`).
2.  **Referencias 煤tiles**:
    *   Revisa `despliegue_comandos.md` para saber c贸mo correr la API localmente.
    *   Consulta `arquitectura.md` para ver c贸mo la API conecta con Hadoop WebHDFS.

---

##  Equipo Frontend (Web Dashboard)

Si trabajas en la interfaz de usuario con **React, Next.js y TailwindCSS**.

1.  **[Documentaci贸n del Frontend](frontend_documentacion.md)**:
    *   Estructura del proyecto Next.js (`/frontend`).
    *   Componentes principales y librer铆as usadas (Recharts, Shadcn/ui).
    *   Gesti贸n de estado y consumo de API con `useSWR`.
2.  **[Gu铆a de Interfaces (UI/UX)](interfaces_gui.md)**:
    *   Dise帽o visual, paleta de colores y experiencia de usuario.
3.  **Para empezar**:
    *   Necesitar谩s correr el backend seg煤n `despliegue_comandos.md` para tener datos reales en tu UI.

---

##  Inicio R谩pido

驴Acabas de llegar? Ejecuta esto para tener todo corriendo en 5 minutos:

1.  `docker-compose up -d --build`
2.  `.\scripts\verify_env.bat` (Espera a que termine)
3.  Abre `http://localhost:3000`
